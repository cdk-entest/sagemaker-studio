---
title: sagemaker estimator
description: sagemaker estimator
author: haimtran
publishedDate: 01/06/2023
date: 2022-06-01
---

## Introduction

[GitHub]() this note shows basics concepts of SageMaker Estimator API

- Estimator: Built-In Algorithm, Framework, BYOM
- Estimator: Training Job
- Estimator: Deploy Endpoint

## Estimator Class

An estimator is an abstraction object with methods for training a model, deploying a model into an endpoint. It means that it will call AWS APIs under the hood to create training job, mode, endpoint, etc. Without this abstraction, it is possible to directly call APIs such as with Boto3 to create model, train, deploy. It has at least the following properties

- Container image (container image uri)
- Instance type which run the container
- IAM Role for accessing S3 (data, code), CloudWatch logs

Estimator class is organized into with based and child classes

- Built-In Algorithm
- Framework Algorithm
- Bring Your Own Model (BYOM)

Let create a estimator for PCA (built-in algorithm) using the based estimator class. First we need to find the iamge uri

```py
image_uri = sagemaker.estimator.image_uris.retrieve(
    framework="pca",
    region=os.environ["REGION"],
    version="0.23-1",
    instance_type="ml.m4.xlarge",
)
```

Then we can create an estimator using the SageMaker based Estimator class

```py
estimator = sagemaker.estimator.Estimator(
InputDataConfig=[
  {
    'ChannelName': 'string',
    'DataSource': {
      'S3DataSource': {
          'S3DataType': 'ManifestFile'|'S3Prefix'|'AugmentedManifestFile',
          'S3Uri': 'string',
          'S3DataDistributionType': 'FullyReplicated'|'ShardedByS3Key',
          'AttributeNames': [
              'string',
          ],
          'InstanceGroupNames': [
              'string',
          ]
      },
      'FileSystemDataSource': {
          'FileSystemId': 'string',
          'FileSystemAccessMode': 'rw'|'ro',
          'FileSystemType': 'EFS'|'FSxLustre',
          'DirectoryPath': 'string'
      }
    },
    'ContentType': 'string',
    'CompressionType': 'None'|'Gzip',
    'RecordWrapperType': 'None'|'RecordIO',
    'InputMode': 'Pipe'|'File'|'FastFile',
    'ShuffleConfig': {
        'Seed': 123
    }
  },
],
    OutputDataConfig={
        'KmsKeyId': 'string',
        'S3OutputPath': 'string'
    },    image_uri=image_uri,
    instance_type="ml.m4.xlarge",
    instance_count=1,
    # output_path="",
    role=os.environ["SAGEMAKER_ROLE"],
)
```

Then we can train the model by calling fit method on the estimator. Under the hood, this method call an API to create a training job [docs](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html). Please check [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_training_job.html) for detail

```py
estimator.set_hyperparameters(
    feature_dim=4,
    num_components=3,
    mini_batch_size=200
)
```

Train the model by creating a training job either by estimator.fit() or other methods to create a training job such as Boto3, TrainingStep in a pipeline.

```py
estimator.fit(inputs={"train": s3_train_data})
```

Finally, we can deploy the model as a endpoint and invoke it. Under the hood, this method call an API to create an serving endpoint config and endpoint [docs](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpoint.html). Please check [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_endpoint_config.html) for detail

```py
predictor = estimator.deploy(
    initial_instance_count=1,
    instance_type="ml.t2.medium"
)
```

Take note the endpoint and invoke. Under the hood, this method send a HTTP request to the endpoint

```py
predictor.predict(clean_ecg[:10000,:])
```

## Estimator Data Access

Basically, trining job run containers with training script, model (image uri), and training data. Since the training data stored in S3, or local, or FileSystem, we need to understand how data is passed from sources to containers. Please check [blog](https://aws.amazon.com/blogs/machine-learning/choose-the-best-data-source-for-your-amazon-sagemaker-training-job/) to select suitable input mode

## Estimator Data Input

There are some options to feed training data into a estimator.fit() for training [docs](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase). Under the hood, it call an API to create an training job with input and output data config as

```json
InputDataConfig=
[
{
    'ChannelName': 'string',
    'DataSource': {
        'S3DataSource': {
            'S3DataType': 'ManifestFile'|'S3Prefix'|'AugmentedManifestFile',
            'S3Uri': 'string',
            'S3DataDistributionType': 'FullyReplicated'|'ShardedByS3Key',
            'AttributeNames': [
                'string',
            ],
            'InstanceGroupNames': [
                'string',
            ]
        },
        'FileSystemDataSource': {
            'FileSystemId': 'string',
            'FileSystemAccessMode': 'rw'|'ro',
            'FileSystemType': 'EFS'|'FSxLustre',
            'DirectoryPath': 'string'
        }
    },
    'ContentType': 'string',
    'CompressionType': 'None'|'Gzip',
    'RecordWrapperType': 'None'|'RecordIO',
    'InputMode': 'Pipe'|'File'|'FastFile',
    'ShuffleConfig': {
        'Seed': 123
    }
},
]
```

The Estimator object provide several options (interface) to feed data into a training job, but under the hood it call an API with the above spec.

- Option 1. [TrainingInput](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/linear_learner_abalone/Linear_Learner_Regression_csv_format.ipynb)

```py
train_data = sagemaker.inputs.TrainingInput(
    s3_train_data,
    distribution="FullyReplicated",
    content_type="text/csv",
    s3_data_type="S3Prefix",
    record_wrapping=None,
    compression=None,
)
validation_data = sagemaker.inputs.TrainingInput(
    s3_validation_data,
    distribution="FullyReplicated",
    content_type="text/csv",
    s3_data_type="S3Prefix",
    record_wrapping=None,
    compression=None,
)
# feed data to estimator for training
linear.fit(inputs={"train": train_data, "validation": validation_data}, job_name=job_name)
```

Another example with PCA [HERE](https://cdk.entest.io/ml/pca-sagemaker)

```py
image_uri = image_uris.retrieve(
    framework="pca",
    region=os.environ["REGION"],
    instance_type="t2.medium",
)
estimator = sagemaker.estimator.Estimator(
    role=config["SAGEMAKER_ROLE"],
    image_uri=image_uri,
    instance_count=1,
    instance_type="ml.c4.xlarge",
)
estimator.set_hyperparameters(
    feature_dim=4,
    num_components=3,
    mini_batch_size=200,
)
estimator.fit(
    inputs={
        "train": TrainingInput(
            content_type="text/csv;label_size=0",
            s3_data=f"s3://{config['SAGEMAKER_BUCKET']}/pca-processed-data",
        )
    }
)
```

- Option 2. [S3 Data Location](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/pca_mnist/pca_mnist.ipynb)

```py
s3_train_data = f"s3://{bucket}/{prefix}/train/{key}"

pca = sagemaker.estimator.Estimator(
    container,
    role,
    instance_count=1,
    instance_type="ml.c4.xlarge",
    output_path=output_location,
    sagemaker_session=sess,
)
pca.set_hyperparameters(
    feature_dim=50000,
    num_components=10,
    subtract_mean=True,
    algorithm_mode="randomized",
    mini_batch_size=200,
)

pca.fit(inputs={"train": s3_train_data})
```

- Option 3. [Local Mode](https://aws.amazon.com/blogs/machine-learning/use-the-amazon-sagemaker-local-mode-to-train-on-your-notebook-instance/)

```py
inputs = sagemaker_session.upload_data(path='data', bucket=bucket, key_prefix='data/cifar10')

cifar10_estimator = PyTorch(
    py_version='py3',
    entry_point='source/cifar10.py',
    role=role,
    framework_version='1.7.1',
    instance_count=1,
    instance_type='local'
)

cifar10_estimator.fit(inputs)
```

## Reference

- [SM Access Data](https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html)

- [SM Training Storage Folder](https://docs.aws.amazon.com/sagemaker/latest/dg/model-train-storage.html)

- [Data Input Mode](https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html)

- [SM Enviornment Variables](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md#sm_channel_channel_name)

- [SM Enviornment Variables and Tensorflow] (https://github.com/aws/amazon-sagemaker-examples/blob/main/frameworks/tensorflow/code/train.py)

- [Simple BYOM](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-script-mode/sklearn/sklearn_byom_outputs.ipynb)

- [Train a Model SageMaker](https://sagemaker.readthedocs.io/en/stable/overview.html#train-a-model-with-the-sagemaker-python-sdk)

- [Train Linear Leaner](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/linear_learner_abalone/Linear_Learner_Regression_csv_format.ipynb)

- [Train PCA Input](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/pca_mnist/pca_mnist.ipynb)

- [Built-In Algorithm No Script Required](https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-choose.html)

- [SM PCA Details](https://docs.aws.amazon.com/sagemaker/latest/dg/pca.html)

- [SM Simple PCA](https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/pca_mnist/pca_mnist.html)

- [Local Mode Data Training](https://aws.amazon.com/blogs/machine-learning/use-the-amazon-sagemaker-local-mode-to-train-on-your-notebook-instance/)

- [Local Mode Detail](https://sagemaker.readthedocs.io/en/stable/overview.html#local-mode)
